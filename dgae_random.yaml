!obj:pylearn2.train.Train {
    dataset: &train !pkl: "%(train_data)s",
    model: !obj:pylearn2.models.gatedautoencoder.DenoisingFactoredGatedAutoencoder {
        nvisX : %(nvisX)i,
        nvisY : %(nvisY)i,
        nfac : %(nfac)i,
        nmap : %(nmap)i,
        act_enc : 'sigmoid',
        act_dec : null,
        irange : 0.01,
        color : False,
        recepF : [%(recepF)i, %(recepF)i],
        corruptor: !obj:pylearn2.corruption.BinomialCorruptor {
            corruption_level: 0.4
        }
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        learning_rate : %(lr)f,
        cost : !obj:pylearn2.costs.gatedautoencoder.SymmetricMSRE {},
        batch_size : %(batch_size)i,
        termination_criterion: !obj:pylearn2.termination_criteria.And {
            criteria: [
                !obj:pylearn2.termination_criteria.EpochCounter {
                    max_epochs: %(max_epochs)i
                }
            ]
        },
        monitoring_dataset :
            {
                'train' : *train,
            },
        learning_rule : !obj:pylearn2.training_algorithms.learning_rule.Momentum {
            init_momentum: 0.5
        },
        monitoring_costs : {
            'Normalized' : !obj:pylearn2.costs.gatedautoencoder.NormalizedSymmetricMSRE {},
        },
    },
    extensions: [
            !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {
            start: 1,
            saturate: 10,
            final_momentum: .9
        },
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
             channel_name: 'train_objective',
             save_path: "dgae_%(nfac)s_%(nmap)s_best.pkl"
        }
    ],
    allow_overwrite: True,
    save_path: "dgae_%(nfac)s_%(nmap)s.pkl",
    save_freq : 10
}
